{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "603dfbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import PandasTools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5a2914",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "\n",
    "Supervised learning algorithms in chemistry make predictions on observables of molecular systems. They are built using a set of training data, usually composed of molecular features and desired observables. This training data can be experimentally obtained, or obtained with computational techniques. Many mathematical models exist which relate the molecular input to a desired output:\n",
    " - k-Nearest Neighbors\n",
    " - Linear Regression\n",
    " - Support Vector Machines (SVM)\n",
    " - Decision Trees\n",
    " - Ensemble Methods\n",
    "\n",
    "There are two major types of SL algorithm: **Classification** and **Regression**. Classification models predict a non-numerical class-label based on inputs. They are very useful to predict certain properties of molecules that don't have inherent numerical values. Regression models predict a real number--a continuous variable--from chemical features.\n",
    "\n",
    "In this notebook, we will learn and execute the main components of building SL models:\n",
    " 1. Analyze and define the task\n",
    " 2. Process training data\n",
    " 3. Train the model\n",
    " 4. Evaluate the model\n",
    " 5. Optimize the model\n",
    " 6. Apply the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afecf630",
   "metadata": {},
   "source": [
    "## Predicting Aqueous Solubility\n",
    "\n",
    "### 1. Defining the Task\n",
    "\n",
    "Solubility in water is a cruicial molecular property in the context of both drug discovery and agrochemistry. It determines the uptake and distribution of compounds throughout the body and our environment. Measuring solubility for a large number of compounds is a very time-consuming undertaking, so we'd like to use ML to avoid the need for physical samples.\n",
    "\n",
    "What type of model should we use in this task?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38ca008",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2408d2ac",
   "metadata": {},
   "source": [
    "### 2. Processing Training Data\n",
    "\n",
    "### Getting the Data\n",
    "We will use the same dataset from the ESOL dataset, which we saw briefly in a previous notebook. The entire dataset is contained in the `esol.csv` file in the `data` folder. Load it into a dataframe called `esol_df`, and print the first five indices and the total number of molecules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d85fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "442a1666",
   "metadata": {},
   "source": [
    "We can see that our dataset has two columns, and 1128 molecules. We'll need some sort of descriptor for these molecules. In the cell below:\n",
    " 1. Store the SMILES strings for all molecules into an array\n",
    " 2. Store the solubilities into an array.\n",
    " 3. Make a new array containing Morgan fingerprints for each molecule, be sure to conver this to a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb99419",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6026fcac",
   "metadata": {},
   "source": [
    "### Featurizers\n",
    "\n",
    "Oftentimes, we can use a program to automate the selection of features. While we can use just the fingerprints we have generated, we can also have our program automatically generate several different descriptors, and use the most important ones.\n",
    "\n",
    "Execute the cell below to download `deepchem`, which we'll use to auto-generate some features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ff1960",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install deepchem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d3835d",
   "metadata": {},
   "source": [
    "Now, execute the following cell to have `deepchem` come up with some features. We'll build models with both these and our fingerprints to evaulate which features lead to better models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81a28f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading some PyTorch models, missing a dependency. No module named 'torch'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch'\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'torch'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of generated molecular descriptors: 209\n"
     ]
    }
   ],
   "source": [
    "from deepchem.feat import RDKitDescriptors\n",
    "featurizer = RDKitDescriptors()\n",
    "auto_features = featurizer.featurize(smiles)\n",
    "print(f\"Number of generated molecular descriptors: {auto_features.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199091f0",
   "metadata": {},
   "source": [
    "Its possible that the program fails to generate features for some molecules. These invalid values will create errors in our models--lets remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e0e5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of molecular descriptors without invalid values: 209\n"
     ]
    }
   ],
   "source": [
    "auto_features = auto_features[:, ~np.isnan(auto_features).any(axis=0)]\n",
    "print(f\"Number of molecular descriptors without invalid values: {auto_features.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5febc10d",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "\n",
    "For any set of features, the next step is always to do feature selection. Feature selection is an essential part of data preprocessing. It involves analyzing all features from a dataset, and removing any features that are redundant or uninportant. What results is a dataset of features that will produce less noisy and more accurate models. Luckily, feature selection is very automated using `sklearn`. \n",
    "\n",
    "`sklearn` is one of the main workhorse modules in data science. We will be constantly using it, as it has automated most routines we'll come across. Execute the cell below to perform the feature selection on our set of fingerprints, we'll also print the number of features we retain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aed9474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of descriptors retained: 1013\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold=0.0)\n",
    "features = selector.fit_transform(fps)\n",
    "\n",
    "print(f\"Number of descriptors retained: {features.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad62baa",
   "metadata": {},
   "source": [
    "Now, repeat this procedure for the auto-generated features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "154278f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of descriptors retained: 190\n"
     ]
    }
   ],
   "source": [
    "selector = VarianceThreshold(threshold=0.0)\n",
    "auto_features = selector.fit_transform(auto_features)\n",
    "print(f\"Number of descriptors retained: {auto_features.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404b8336",
   "metadata": {},
   "source": [
    "We can see that some of the descriptors were removed.\n",
    "\n",
    "\n",
    "### Data Partitioning\n",
    "Once all of our molecules are featurized, we need to split the data into the **training** and **testing** sets. The training set is the set of features/values used to build the model. The testing set is used to evaluate the model. These datasets need to be kept separated, to avoid any bias in building the model. Again `sklearn` has a very useful function to automatically split the dataset based on a user-specified size.\n",
    "\n",
    "I've filled out the function for you, but print the sizes of the training and testing sets below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04fa7602",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902 226\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(\n",
    "    features, y, train_size=0.8, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7985cbd0",
   "metadata": {},
   "source": [
    "Now generate test/train sets of the auto-featurized data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34fc6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "089eb070",
   "metadata": {},
   "source": [
    "We still have one step to do before we can train a model, especially since we will be building some models from auto-featurization. Features of different types (say, molecular weight, electrochemical potential, etc) will have values that potentially span very different orders of magnitude. Large differences can cause massive instabilities in ML models, so we need to perform a normalization of the features. \n",
    "\n",
    "In the cell below, we'll normalize the features of our set of only fingerprints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "541ecffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(xtrain)\n",
    "\n",
    "x_train_ori = xtrain\n",
    "x_test_ori = xtest\n",
    "\n",
    "xtrain = scaler.transform(xtrain)\n",
    "xtest=scaler.transform(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6f936d",
   "metadata": {},
   "source": [
    "and the auto-generated set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6358cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dea95fa",
   "metadata": {},
   "source": [
    "Do you think it matters that we normalize the training data separate from the test data? Why or Why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2f8cec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e975fe98",
   "metadata": {},
   "source": [
    "What are the main steps in data preparation? Why is each one needed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3a7645",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "205072be",
   "metadata": {},
   "source": [
    "## 3. Training and Evaluating the Model\n",
    "\n",
    "Finally! As you can see, the bulk of the work in building a ML model is in carefully preparing the data. When building a model, its always best to test a few out, and see which performs the best for the task at hand. Here, we'll test a random forest and a gradient boosting regressor, which are both ensemble models.\n",
    "\n",
    "Initialize the models below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3c2eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "ranf_reg = RandomForestRegressor(n_estimators=10, random_state=0) \n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gb_reg = GradientBoostingRegressor(n_estimators=10, random_state=0)  # using 10 trees and seed=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d912c02a",
   "metadata": {},
   "source": [
    "Next, we'll define a function that trains a model, tests it, and prints the error in test set predictions. To evaluate the models, we'll use the root mean squared error,\n",
    "$$ RMSE = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}(y_i - \\hat{y}_i)^2} $$\n",
    "\n",
    "Excecute the cell below to initialize the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29df19e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def train_test_model(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Function that trains a model, and tests it.\n",
    "    Inputs: sklearn model, train_data, test_data\n",
    "    \"\"\"\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate RMSE on training\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    model_train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "    model_test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "    model_train_rmse = model_train_mse ** 0.5\n",
    "    model_test_rmse = model_test_mse ** 0.5\n",
    "    print(f\"RMSE on train set: {model_train_rmse:.3f}, and test set: {model_test_rmse:.3f}.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02105d2",
   "metadata": {},
   "source": [
    "Now let's use this function. In the cell below, complete the function calls with the apropriate data sets. Then execute the cell to see how they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2132813d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Descriptor: Morgan Fingerprint\n",
      "RMSE on train set: 0.542, and test set: 1.386.\n",
      "\n",
      "Model: Gradient Boost\n",
      "Descriptor: Morgan Fingerprint\n",
      "RMSE on train set: 1.628, and test set: 1.889.\n",
      "\n",
      "Model: Random Forest\n",
      "Descriptor: Auto-generated\n",
      "RMSE on train set: 0.278, and test set: 0.723.\n",
      "\n",
      "Model: Gradient Boost\n",
      "Descriptor: Auto-generated\n",
      "RMSE on train set: 1.029, and test set: 1.189.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and test the random forest model\n",
    "print(\"Model: Random Forest\")\n",
    "print(\"Descriptor: Morgan Fingerprint\")\n",
    "train_test_model()\n",
    "\n",
    "# Train and test Gradient Boost model\n",
    "print(\"Model: Gradient Boost\")\n",
    "print(\"Descriptor: Morgan Fingerprint\")\n",
    "train_test_model( )\n",
    "\n",
    "# Train and test the random forest model\n",
    "print(\"Model: Random Forest\")\n",
    "print(\"Descriptor: Auto-generated\")\n",
    "train_test_model()\n",
    "\n",
    "print(\"Model: Gradient Boost\")\n",
    "print(\"Descriptor: Auto-generated\")\n",
    "train_test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5768358",
   "metadata": {},
   "source": [
    "Which ML algorithm was the most accurate? How can you evaluate this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f8ec29",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "444b9241",
   "metadata": {},
   "source": [
    "Which featurization led to more accurate models? Why"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9d7808",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02b1ffdf",
   "metadata": {},
   "source": [
    "### 4. Optimizing the model\n",
    "\n",
    "Nearly all ML models use some sort of parameterization beyond the training data. For example, in both ensemble models we used, we had to provide a `n_estimators` parameter. This parameter is used to determine the number of trees in tree-based models. We can also toggle the tree depth with a `max_depth` paramter. Using automated tools, we can optimize both of these *hyperparameters* to improve our models. \n",
    "\n",
    "Execute the cell below to perform the optimization. You'll need to choose the training data. This step may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a123243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 20, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, 20, 30]\n",
    "}\n",
    "\n",
    "# use 5-folds cross validation during grid searching\n",
    "grid_search = GridSearchCV(RandomForestRegressor(random_state=0), param_grid, cv=5)\n",
    "\n",
    "# Put in your x and y training values here\n",
    "grid_search.fit()\n",
    "\n",
    "\n",
    "# Print the parameters\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d979c928",
   "metadata": {},
   "source": [
    "In the cell below, use your optimized parameters to train and test a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7afc5f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on train set: 0.245, and test set: 0.687.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56f5482e",
   "metadata": {},
   "source": [
    "How did the hyperparameterization affect your testing and training errors? Were you surprised by these results at all?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b5b5b9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6591f653",
   "metadata": {},
   "source": [
    "### 6. Applying the Model\n",
    "\n",
    "Now that you've trained and optimized your model, we can try to apply it to some new molecules. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3091c49",
   "metadata": {},
   "source": [
    "**1. Get your Molecules.** We are going to apply our ML model on some preclinical drug molecules currently in development to treat SARS-COV2. To find these molecules, go to the ChEMBL website, https://www.ebi.ac.uk/chembl/. In the homescreen, click the right arrow on the center image until \"Explore SARS-CoV2 Data\" appears. Then, click the icon that says \"Compounds\". \n",
    "\n",
    "You will then see a grid of many molecules. Use the filter on the left to display only small molecule, preclinical drug molecules. Then, store the SMILES string of **five** compounds in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25839cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "573a483c",
   "metadata": {},
   "source": [
    "**2. Visualize your Compounds.** Using your SMILES strings, display your compounds in a grid. You do not need to label them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716b00b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dd7a273",
   "metadata": {},
   "source": [
    "**3. Generate Features.** Again using your SMILES strings, generate features for each molecule, and use the selector from above to perform feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9eafc5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Recall what function we used to get features from smiles strings\n",
    "## Auto-generate your features here\n",
    "\n",
    "\n",
    "## 2. Next, use the selector to perform feature selection. Above, we used training data to \n",
    "##    do this. Here, we just use the same selector to transform our data. The command we need is\n",
    "##    selector.transform()\n",
    "## Perform feature selection here\n",
    "\n",
    "\n",
    "## 3. Now, pass these features to the model. The model can take the whole list of molecules\n",
    "##    and do all predictions together. The function you need is your_model.predict(your_features)\n",
    "##    This will return an array of predictions, in the order given\n",
    "## Predict solubilities below, print the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a563fd70",
   "metadata": {},
   "source": [
    "**4. Chemical Analysis.** How soluble are the molecules you found? What implications might this have on their efficacy as therapeutics?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b0574a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ce082b5",
   "metadata": {},
   "source": [
    "**5. Model Analysis.** On ChEMBL, you can find solubilities listed as AlogP in the chemical properties table. How well do the results from your model match those on ChEMBL? What might account for any differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8e96b6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f95651f",
   "metadata": {},
   "source": [
    "**6. More Model Analysis.** Suggest one test you could run to determine why your model does or does not accurately predict the solubilities of the compounds you found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd242e00",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

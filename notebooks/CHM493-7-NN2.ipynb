{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7512ee94-1c84-4b5d-acaf-90e849fe2171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MACCSkeys, Draw, rdFingerprintGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00da7806-2dc3-4f58-8bc9-b47f3fe80894",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install numpy==1.23.5\n",
    "!pip install keras==2.9.0 \n",
    "!pip install -U tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece03a1-43ca-41a6-9453-547f1354b06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install deepchem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b4962a-2712-4368-803b-226fe61961ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Conv1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import L1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a4b143-f8cd-49de-a122-1d3bcafcd063",
   "metadata": {},
   "source": [
    "***Make sure the above cells all run properly***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddb36c8-faa2-4309-bd84-e4df0ffb7d17",
   "metadata": {},
   "source": [
    "# Geometry-based Descriptors for Neural Networks\n",
    "\n",
    "All of our notebooks this far have used descriptors that are in some way derived from a SMILES string. SMILES strings only specify molecular identity and connectivity, but they cannot encode a specific molecule's geometry. For example, a SMILES string could not be used to generate a ML-based force field, where the model would need to predict the total energy as a function of changing molecular geometry. \n",
    "\n",
    "There are many choices for geometry-based descriptors. The simplest choice is the Coulomb matrix, a 2D descriptor, which encodes the molecular geometry using nuclear charges and distances. A given element of the Coulomb matrix can be defined using the charges of any pair of atoms ($q_Aq_B$) and their distance, $r_{AB}$:\n",
    "\n",
    "$$C_{AB} = \\frac{q_Aq_B}{r_{AB}}$$\n",
    "\n",
    "More sophistocated descriptors use symmetry functions, which encode the local environments of each atom beyond a pairwise interaction.\n",
    "\n",
    "## Interatomic Potentials based on Machine Learning\n",
    "\n",
    "One of the main goals of all computational chemists is to accurately compute the total energy of molecules. However, there does not exist a theory that can be universally used for all molecules. Quantum mechanical methods tend to be limited to small molecules (<50 heavy atoms), since their cost (in terms of memory/time) scale with the number of electrons.\n",
    "\n",
    "Larger systems, like proteins, membrane models, etc., cannot be easily modeled with quantum mechanical methods, so classical methods are typically used, often called \"molecular mechanics\". Molecular mechanics involve simple, inexpensive physical models that depend only on atom positions and locations, and not on the electronic structure. While very useful, MM methods depend a lot on their parameterization, and their degree of reliability is limited.\n",
    "\n",
    "It becomes a tantalizing possibility, then, that we could use machine learning to bring the accuracy of a QM method to the cost of a MM method. Indeed, this is the goal of many reseach laboratories, with the most successful example being the ANI potential. ANI is a NN-based ML model that was trained on DFT energies of about ~2 million small molecules. ANI has made it possible to calculate DFT-quality energies for a variety of molecules at a cost comparable to most MM methods. The success of ANI has led to the developmet of many ML models designed to predict quantum mechanically-derived quantities. \n",
    "\n",
    "In this notebook, you will be builing your own molecular potential based on QM energies. You will be using the QM9 dataset, which is composef of roughly 130,000 molecules containing 9 heavy atoms. This dataset also contains a number of molecular properties, like the dipole moment, total energy, and zero-point energy correciton, all computed at the B3LYP/6-31G(2df,p) level of theory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef84476-8347-4932-84dd-b291a99a1a50",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "The QM9 dataset is so commonly used, that `DeepChem` has a function to load, featurize, normalize, and split the data all in one function. \n",
    "\n",
    "All we need to do is define a featurizer, here we'll choose the Coulomb matrix, and then pass to the function `get_qm9()` defined in DeepChem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fa5222-0ff4-4bec-9bf4-3c04b084104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a featurizer below\n",
    "\n",
    "# Pass it to the function\n",
    "tasks, datasets, transformers = deepchem.molnet.load_qm9(featurizer= )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4788cd7d-8b0c-4502-8320-292a7a23e655",
   "metadata": {},
   "source": [
    "The `tasks` list tells is what data is available for training. Print it below to see the values, and look at the `DeepChem` documentation to get their definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a453f3f-b17f-4107-a0da-3064376707f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94eefc66-64a9-46b1-a60b-d89a3f1fda45",
   "metadata": {},
   "source": [
    "The `datasets` list contains the training, validation, and testing set descriptors and labels. We will use the training set to train the model, and the validation set is used at each epoch to estimate the accuracy. The testing set is only used to test the completed model, after it is trained. \n",
    "\n",
    "As usual, we need to do a little formatting of the data. First, we need to store each feature/label pair in a well-named list. I'll do what's needed on the training set, but repeat the procedure for the validation and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b875e7-bd6f-43b4-b1ce-2eb3e87d203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we unroll the datasets\n",
    "train, valid, test = datasets\n",
    "\n",
    "# Then we grab the features, store them as x and y\n",
    "xtrain = train.X\n",
    "ytrain = train.y\n",
    "\n",
    "# We need to make sure the features are the right dimension\n",
    "x_train = np.reshape(x_train, (len(x_train), 32*32))\n",
    "\n",
    "# Let's see how many training points we're using\n",
    "print(len(x_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799335eb-f666-40d9-bb33-fa76d07d6533",
   "metadata": {},
   "source": [
    "Now we need to select our labels. The lists contain all available data defined in the `tasks` list. We need to take our sets of y values, and create lists that only contain the label we want. In our case, this is the total energy, `u0`. Follow the comments below to create the three lists we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e91a76a-301a-4765-ab74-f31e4c339477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, determine the index of 'u0'. This will tell us what column from the y-values we need.\n",
    "\n",
    "# Next, define a list of y-values (e.g., start with ytrain), as the slice\n",
    "# of values at the index you defined\n",
    "\n",
    "\n",
    "# Then, flatten the lists. Be sure they have nice names\n",
    "# like ytrain, yvalid, and ytest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db92061-bbd1-496f-814f-8cd1a4f0ac56",
   "metadata": {},
   "source": [
    "## Defining and training your model\n",
    "\n",
    "Now that you have the data in the proper format, you need to define your model architecture. Despite the programmingnot being too demanding, this is a very challenging task. There are many choices here, but we'll stick to the same sequential models from the previous notebook. One addition you may want to consider a few things:\n",
    "\n",
    " 1. Have your first layer have a number of nodes equal to your **total** number of features per molecule.\n",
    " 2. Have the next few layers reduce the number of nodes to something more modest.\n",
    " 3. Consider adding one or more **dropout layers**. These randomly set node values to zero, and are implemented to avoid overfitting.\n",
    " 4. Try having a somewhat large number of layers. You may want to use a loop for that.\n",
    " 5. We are ultimately learning a single number---the total energy---so your last layer should only have a single node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77ec656-c385-445d-86c9-a67f5b063b62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69a08a60-5873-4143-b837-4d3f75074cfa",
   "metadata": {},
   "source": [
    "Compile the model below. If you notice your model converges to a high-loss value very quickly, consider changing the **learning rate**, by passing a value to the compiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c0d71b-0240-4e8d-a31c-2cc427fbd50a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc1790f0-04cf-4eba-b7c2-95483542673a",
   "metadata": {},
   "source": [
    "Finally, train your model. I'd recommend using a somewhat large batch size, and be sure to remove the `verbose=0` parameter so that you can monitor the loss in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a104a7-65f6-4ad1-9538-a66131436759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "642e5dc7-3394-4fcb-ab70-1936627b8cb9",
   "metadata": {},
   "source": [
    "## Testing and evaluation\n",
    "\n",
    "In the cell below, test your model by following these steps:\n",
    "\n",
    "  1. Use your model to predict the energies of the test set. You will need to flatten the resulting list.\n",
    "  2. Plot your predicted test values against the actual test values. Also plot the y=x line\n",
    "  3. Calculate the RMSE and $R^2$ for the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f25be39-bd65-4e24-92c2-3d021aa36f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0710dc-345a-4fec-a483-44a42f10f0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

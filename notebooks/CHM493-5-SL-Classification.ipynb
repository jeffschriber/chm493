{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bffafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3c5e7e",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "Classification is a type of supervised learning, where non-numerical values are the target of the model. In this notebook, you will build a classification model to determine if a given compound is considered toxic or non-toxic. While toxicity can certiainly be quantified numerically, a simpler model that can do the binary classification between toxic and non-toxic is an extremely useful first step in drug development projects.\n",
    "\n",
    "To train such a model, we will use the ToxCast dataset. ToxCast is a large dataset containin toxicolodgy data for many compounds based on in vitro high-throughput screening. Building a model to predict this toxicological data will let us know if a molecule has potential to be a drug without needing to synthesize it.\n",
    "\n",
    "To build the model, you will need to follow the same steps we saw for regression:\n",
    " 1. Prepare data\n",
    " 2. Featurization\n",
    " 3. Splitting the Data\n",
    " 4. Train the model\n",
    " 5. Evaluate the model\n",
    " 6. Apply the model\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9893d6",
   "metadata": {},
   "source": [
    "## 1. Prepare Data\n",
    "\n",
    "First, load the data file, `toxcast_data.csv` located in the `data` folder, into a pandas dataframe. Name your dataframe `df_tox_unprocessed`, and print the first three rows in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6d8356",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tox_unprocessed = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93129d10",
   "metadata": {},
   "source": [
    "We see that there are a lot of columns. For simplicity, we'll only use the `TOX21_TR_LUC_GH3_Antagonist` column. \n",
    "\n",
    "Execute the cell below update our dataframe with only the data we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6aa212",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tox = df_tox_unprocessed.loc[:,[\"smiles\",\"TOX21_TR_LUC_GH3_Antagonist\"]].dropna()\n",
    "df_tox.columns = [\"smiles\", \"toxic\"]\n",
    "print(df_tox.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d842d3",
   "metadata": {},
   "source": [
    "In the cell below, print the total number of molecules, and print how many of them are toxic. Then, execute the cell that follows to visualize and print a few of the molecules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aceac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d573d84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some of the molecules of this dataset\n",
    "n=6\n",
    "smiles = df_tox.smiles.sample(n).values\n",
    "legend = df_tox.toxic.sample(n).values\n",
    "molecs = [Chem.MolFromSmiles(s) for s in smiles]\n",
    "\n",
    "Draw.MolsToGridImage(\n",
    "    molecs,\n",
    "    subImgSize=(600,300),\n",
    "    legends=[\"Toxic\" if i==1 else \"Non toxic\" for i in legend])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c848cb3f",
   "metadata": {},
   "source": [
    "## 2. Featurization\n",
    "\n",
    "Next, we need to generate features. For this exercise, we'll only use the auto-featurizer.\n",
    "\n",
    "In the cell below, generate the features for all molecules. We cannot do this in one line as before, since some of our SMILES strings are invalid (an unfortunate truth of large datasets). So, you'll need to generate the feature vector manually:\n",
    "\n",
    "   1. Create a list of the SMILES strings from the dataframe\n",
    "   2. For each element in this list, generate the features usint the RDKitDescriptors auto-featurizer\n",
    "   3. Append these features to a list, called `auto_features`\n",
    "   4. Print the length\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc48a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.feat import RDKitDescriptors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43190c5d",
   "metadata": {},
   "source": [
    "Since some of our SMILES are invalid, you'll notice that the code produced a few warnings. DeepChem could not calculate features for these molecules, so we'll need to remove them and the corresponding toxicity label.\n",
    "\n",
    "Run the cell below to filter the correct molecules. We'll store the valid features as `X` and the corresponding targets as `y`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455b6502",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do not edit this cell\n",
    "\n",
    "tox_vals = df_tox['toxic'].values\n",
    "\n",
    "feat_len = featurizer.featurize(\"CCC\").shape[1]\n",
    "\n",
    "bad_mols = []\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for n,item in enumerate(auto_features):\n",
    "    if np.isnan(item[0]).any():\n",
    "        continue    \n",
    "    elif len(item[0]) == feat_len:\n",
    "        X.append(item[0])\n",
    "        y.append(tox_vals[n])\n",
    "    else:\n",
    "        bad_mols.append(n)\n",
    "\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e700e46",
   "metadata": {},
   "source": [
    "In the cell below, perform the feature selection and print the number of features retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defc75d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "759c3e89",
   "metadata": {},
   "source": [
    "## 3. Data Splitting\n",
    "\n",
    "In the cell below, split your data set into training and testing subsets. Then, normalize your features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c047ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c56ec5",
   "metadata": {},
   "source": [
    "## 4. Model Selection and Training\n",
    "\n",
    "We're going to test three different models to do our classification.\n",
    "\n",
    "In the cell below, initialize a random forest classifier, using 300 estimators and a max depth of 10. Then, train the model. You do not need to create a function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521bafca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_cls = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48004ed5",
   "metadata": {},
   "source": [
    "Repeat this step for two other models. You can use any classification model, including Logistic Regression, Support Vector Machines, Gradient Boosting, or any other you find on the sklearn documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3491018f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1017672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f038fb65",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation\n",
    "\n",
    "To evaluate our models, we are going to use three metrics:\n",
    "\n",
    " - Accuracy Score. The accuracy score is the fraction of correctly classified labels.\n",
    " - AUC ROC. This is the area under the receiving operating characteristic curve, shown below. The x-axis is the **false positive rate**, and the y axis is the **true positive rate**. A larger AUC indicates that a model is both sensitive and selective in its classification.\n",
    " - F1 score. This is another metric that combines the precision and recall of a model. It is a more honest metric compared to just the accuracy, since it accounts for any imbalance among the testing group.\n",
    "\n",
    "\n",
    "First, we need to make the predictions on our testing set. Complete the cell below by passing your testing set features into the function. Then, reproduce the function to make predictions with your remaining two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e5f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf_clf.predict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebd2ad8",
   "metadata": {},
   "source": [
    "Now, calculate the accuracy score, ROC AUC, and f1 score for each of your models. I'll demonstrate how to do it for the random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f240a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "\n",
    "acc_rf = accuracy_score(ytest, y_pred_rf)\n",
    "print(f\"Accuracy of Random Forest Classifier is {acc_rf:.3f}\")\n",
    "auc_rf = roc_auc_score(ytest, y_pred_rf)\n",
    "print(f\"ROC-AUC of Random Forest Classifier is {auc_rf:.3f}\")\n",
    "f1s_rf = f1_score(ytest, y_pred_rf)\n",
    "print(f\"F1 Score of Random Forest Classifier is {f1s_rf:.3f}\")\n",
    "\n",
    "# Calculate the three metrics for your remaining two models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ee5acf-7dd1-443d-87b8-3fd24cf3bfd2",
   "metadata": {},
   "source": [
    "A very convenient way to analyze a classification model is using a confusion matrix. It is perhaps the most complete way to analyze a classification model. Confusion matrices plot the numbers of true positives (good), false positives (bad), true negatives (good), and false negatives (bad). \n",
    "\n",
    "Complete the function call below to plot the confusion matrix for one of your models. Then, copy the code in the remaining two cells to plot the confusion matrices for your remaining models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3584a2-f672-4de9-91c6-861707c7c022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# This function takes the correct test values as the first parameter\n",
    "# and the predicted values as the y parameter\n",
    "cm = confusion_matrix( , , labels=rf_clf.classes_)\n",
    "\n",
    "#Don't change any of this below\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf_clf.classes_) \n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1e6155",
   "metadata": {},
   "source": [
    "## 6. Apply the Model\n",
    "\n",
    "Now, we need to apply the model to molecules of interest. We'll use a function that we can call many times for different molecules. The function will take two inputs: first a SMILES string for a molecule, and second the trained model you want to use. Complete the template below to make this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1786d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "def is_this_toxic(smiles, model):\n",
    "    \"\"\"\n",
    "    Ask model if the input molecule (smiles) is toxic or not.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate a Molecule from SMILES\n",
    "    mol = \n",
    "\n",
    "    # Calculate features\n",
    "    X_my_mol = \n",
    "    \n",
    "    # I'll do some cleaning\n",
    "    X_my_mol = X_my_mol[:, ~np.isnan(X_my_mol).any(axis=0)]\n",
    "    \n",
    "    \n",
    "    # Perform the feature selection using\n",
    "    # the same transformer\n",
    "    # Be sure to normalize the features\n",
    "    X_my_mol = \n",
    "    X_my_mol = \n",
    "\n",
    "    \n",
    "    # Get model prediction\n",
    "    is_toxic =\n",
    "\n",
    "    # The of the function will draw the molecule and print a statement about its toxicity\n",
    "    is_toxic = \"This molecule is toxic!\" if is_toxic else \"This is not toxic :)\"\n",
    "\n",
    "    img = Draw.MolsToGridImage(\n",
    "        [mol],\n",
    "        subImgSize=(600,300),\n",
    "        legends=[is_toxic],\n",
    "        molsPerRow=1\n",
    "    )\n",
    "    display(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5915bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c2f239a-37d6-4ee0-ac74-cfe124f20f43",
   "metadata": {},
   "source": [
    "In the cells below, test your function on five poisonous molecules, and see what your models predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af8a9e2-d107-424c-88ce-7c9a622e4a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f053f38-6a23-4e7f-a4da-07ea223175e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437c8f2b-4674-47b6-bf32-3e67228845b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397bcdd5-79f6-470f-88c2-df93906aebd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faebf29a-db33-45fa-830e-c9ef26df93d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f22c10bf-ee5d-4004-9724-03479814c6a7",
   "metadata": {},
   "source": [
    "Do your results surprise you? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f842647-7dfa-4c8e-8e03-9e4bcc7ec886",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c5d3424-560b-4072-a8a1-b3e83d3ebf98",
   "metadata": {},
   "source": [
    "Looking back a the testing errors in part 5, do you think high accuracies in our testing data is reliable? Why might the accuracy be high compared to the other metrics?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d980ef15-148b-49b9-824b-93c64a194fcb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1956d399-88f0-4cc1-ae3d-f8efa30b21ad",
   "metadata": {},
   "source": [
    "How do the confusion matrices compare across all three models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9c9abc-3699-4c57-bfdf-9b1db412c728",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f6be860-32de-47c9-bd3e-90698a25a52b",
   "metadata": {},
   "source": [
    "Based on all metrics, do you think your models are very suceptible to false positives, false negatives, or both? Use evidence in your answer. Finally, discuss which of your models you think is the best to use for toxicity classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def72a76-790c-4f38-a31f-8626a360d67f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4515e16a-af69-4a01-b2bf-abfd1ec776d1",
   "metadata": {},
   "source": [
    "Discuss the limitations of your models. In what contexts are your models most appropriately applied? Also, how might you improve your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef5f1e8-72aa-4af8-8835-f1922ff5b5a3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
